{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz9BYpozL4V1",
        "outputId": "b75b4e42-f3fb-4349-cd01-09885dd32313"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index\n",
        "!pip install langchain\n",
        "!pip install pyttsx3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GxweCFpFcpYA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\gabri\\OneDrive\\Documents\\Projects\\Hackathones\\HackathonChatGPT\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from llama_index import SimpleDirectoryReader, GPTListIndex, GPTVectorStoreIndex, LLMPredictor, PromptHelper # GPTSimpleVectorIndex\n",
        "from llama_index import ServiceContext, StorageContext, load_index_from_storage\n",
        "from langchain import OpenAI\n",
        "import openai\n",
        "import sys\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EEKfcprVc5jA"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "# !export OPENAI_API_KEY=\"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\"\n",
        "openai.api_key = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wcrBu-iEhn8D"
      },
      "outputs": [],
      "source": [
        "def createVectorIndex(path):\n",
        "  max_input = 4096\n",
        "  tokens = 256\n",
        "  chunk_size = 600\n",
        "  max_chunk_overlap = 20\n",
        "  chunk_overlap_ratio = 1\n",
        "\n",
        "  prompt_helper = PromptHelper(context_window=max_input, num_output=tokens, chunk_overlap_ratio=chunk_overlap_ratio, chunk_size_limit=chunk_size)\n",
        "\n",
        "  # Definir LLM\n",
        "  llmPredictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-003\", max_tokens=tokens, openai_api_key=\"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\"))\n",
        "\n",
        "  # Cargar data\n",
        "  docs = SimpleDirectoryReader(path).load_data()\n",
        "\n",
        "  # Crear vector index\n",
        "  service_context = ServiceContext.from_defaults(llm_predictor=llmPredictor, prompt_helper=prompt_helper)\n",
        "  vectorindex = GPTVectorStoreIndex.from_documents(docs, service_context=service_context)\n",
        "  vectorindex.storage_context.persist()\n",
        "  # vectorindex = GPTVectorStoreIndex(documents=docs, llm_predictor=llmPredictor, prompt_helper=prompt_helper)\n",
        "\n",
        "  return vectorindex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RgD-Rs0odk9p"
      },
      "outputs": [],
      "source": [
        "vectorIndex = createVectorIndex('dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyttsx3\n",
        "engine = pyttsx3.init()\n",
        "voice = engine.getProperty('voices')\n",
        "\n",
        "# engine.setProperty('rate', 150)\n",
        "# # engine.setProperty('volume', 1.0)\n",
        "# engine.setProperty('voice', 'english-us')\n",
        "# engine.say('Hello World')\n",
        "# engine.runAndWait()\n",
        "\n",
        "# voices = engine.getProperty('voices')\n",
        "# for voice in voices:\n",
        "#     print(voice, voice.id)\n",
        "#     engine.setProperty('voice', voice.id)\n",
        "#     engine.say('The quick brown fox jumped over the lazy dog.')\n",
        "#     engine.runAndWait()\n",
        "#     engine.stop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ySwfJsmZnj5m"
      },
      "outputs": [],
      "source": [
        "from speech import extract_text_from_voice\n",
        "\n",
        "def chatbot():\n",
        "  # rebuild storage context\n",
        "  storage_context = StorageContext.from_defaults(persist_dir='./storage')\n",
        "  # load index\n",
        "  vIndex = load_index_from_storage(storage_context)\n",
        "  query_engine = vIndex.as_query_engine()\n",
        "\n",
        "  while True:\n",
        "    prompt = extract_text_from_voice()\n",
        "    prompt = input('Me: ')\n",
        "    if prompt == 'exit':\n",
        "      break\n",
        "    # response = vIndex.query(prompt, response_mode=\"compact\")\n",
        "    response = query_engine.query(prompt)\n",
        "    engine.say(response)\n",
        "    engine.runAndWait()\n",
        "    print(f\"MJ: {response}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MJ: \n",
            "I am Michael Jordan.\n",
            "\n",
            "MJ: \n",
            "No, I do not play basketball.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "chatbot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
